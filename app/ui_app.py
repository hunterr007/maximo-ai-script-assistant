import streamlit as st
from sentence_transformers import SentenceTransformer
from search_scripts import search_scripts
import subprocess

# -------------------- LLM Generator via Ollama --------------------
def generate_script_from_llm(prompt):
    model_name = "mistral:latest"  
    try:
        result = subprocess.run(
            ["ollama", "run", model_name, prompt],
            capture_output=True,
            text=True
        )
        return result.stdout.strip()
    except Exception as e:
        return f"‚ùå Error generating script from LLM: {e}"

# -------------------- Load Embedding Model --------------------
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

# -------------------- Streamlit UI --------------------
st.set_page_config(page_title="Maximo AI Script Assistant", layout="wide")
col1, col2 = st.columns([1, 6])  
with col1:
    st.image("data/Logo.jpg", width=100) 
with col2:
    st.markdown("<h2 style='padding-top: 12px; margin-bottom: 0;'>üõ†Ô∏è Maximo AI Script Assistant</h2>", unsafe_allow_html=True)

st.markdown("<div style='margin-top: 20px;'></div>", unsafe_allow_html=True)

# Description label with tighter spacing to textarea
st.markdown(
    """
    <p style='font-size: 18px; font-weight: 100; margin-bottom: 5px;'>
        Enter a Requirement or Description:
    </p>
    """,
    unsafe_allow_html=True
)

# Text area
user_prompt = st.text_area(
    label="",
    placeholder="e.g., If Work order's work type is CM then make work order failure code mandatory",
    height=100
)


col1, col2 = st.columns([1, 1])
with col1:
    search_btn = st.button("Search", use_container_width=True)
with col2:
    reset_btn = st.button("Reset", use_container_width=True)

# -------------------- Reset Button Logic --------------------
if reset_btn:
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    st.rerun()

# -------------------- Search Button Logic --------------------
if search_btn and user_prompt.strip():
    st.info("üîç Searching for matching script in dataset...")
    results = search_scripts(user_prompt, embedding_model)

    if results:
        for r in results:
            if r.get("name") == "Generated by LLM":
                st.warning("‚ö† No match found. This script was generated by LLM.")
                st.markdown("### üí° Generated Script (LLM Output)")
            else:
                st.success("‚úÖ Match found in dataset.")
                st.markdown(f"**Name:** {r['name']}")
                st.markdown(f"**Launch Point:** {r.get('launch_point_name', '-')}")
                st.markdown(f"**Object Type:** {r.get('launch_point_object', '-')}")
                st.markdown(f"**Similarity Score:** {r.get('similarity', 0):.2f}")
            st.code(r["script_code"], language="python")

    else:
        st.warning("‚ö† No match found in dataset. Generating script using LLM...")
        llm_output = generate_script_from_llm(user_prompt)
        st.markdown("### üí° Generated Script (LLM Output)")
        st.code(llm_output, language="python")
