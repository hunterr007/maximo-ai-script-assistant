import os
import json
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from suggest_script import suggest_script

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_FILE = os.path.join(BASE_DIR, "data", "automation_scripts.json")
EMBEDDING_FILE = os.path.join(BASE_DIR, "embeddings", "script_embeddings.npy")
ID_MAP_FILE = os.path.join(BASE_DIR, "embeddings", "id_map.json")

print("****Inside Search Script****")
with open(DATA_FILE, "r") as f:
    scripts = json.load(f)

with open(ID_MAP_FILE, "r") as f:
    id_map = json.load(f)

script_embeddings = np.load(EMBEDDING_FILE)

def search_scripts(prompt, embedding_model, top_k=3, threshold=0.6):
    prompt_embedding = embedding_model.encode([prompt])
    similarities = cosine_similarity(prompt_embedding, script_embeddings)[0]
    sorted_indices = np.argsort(similarities)[::-1]

    results = []
    for idx in sorted_indices[:top_k]:
        if similarities[idx] >= threshold:
            script = id_map[str(idx)]  # ✅ Use the full script dict directly
            script["similarity"] = float(similarities[idx])
            results.append(script)
            return results

    # ✅ LLM fallback logic
    if not results:
        print("⚠️ No good match found in embeddings. Calling LLM now...")
        llm_script = suggest_script(prompt)
        return [{
            "name": "Generated by LLM",
            "launch_point_name": "N/A",
            "launch_point_type": "N/A",
            "launch_point_object": "N/A",
            "description": prompt,
            "script_code": llm_script,
            "similarity": 0.0
        }]

    return llm_script
